import copy

import matplotlib.pyplot as plt
import torch
from detectron2.structures import Boxes, pairwise_iou
from detectron2.utils.visualizer import GenericMask
import random
import numpy as np
import os
from PIL import Image
folder = '/media/dell/codes/liyiming/CIL/otsu/'
import torchvision.transforms as transforms
import matplotlib.pyplot as plt


def adjust_box_position(new_box, mask, data, iou_threshold=0.005, max_attempts=50):
    img_height, img_width = mask.shape  # (800, 800)
    target_height, target_width = new_box[0], new_box[1]    # 新目标尺寸(target_height, target_width)
    max_distance = 50   # 回放的旧目标框距离新目标框的距离不超过max_distance
    top, bottom, left, right = [], [], [], []
    top_score, bottom_score, left_score, right_score = [], [], [], []
    # 限制条件：新目标的中心点(new_center_x, new_center_y)需要保证新目标不超出图像
    new_center_x_left, new_center_x_right = target_width // 2, img_width - 1 - target_width // 2
    new_center_y_top, new_center_y_bottom = target_height // 2, img_height - 1 - target_height // 2
    """ 从限制条件内选取top的中心点 """
    attempt = 0
    while attempt < max_attempts:
        # 随机选取一个新目标target
        target = random.choice(data['instances'])
        if target._fields['gt_classes'] in [0, 1, 2]:
            continue
        # 获取新目标的中心点(center_x, center_y)以及宽度center_width和高度center_height
        center_box = target._fields['gt_boxes']
        cxmin, cymin, cxmax, cymax = center_box.tensor.to('cpu').numpy()[0].astype(int)
        center_x, center_y = (cxmax + cxmin) // 2, (cymax + cymin) // 2
        center_width, center_height = (cxmax - cxmin), (cymax - cymin)
        # 随机选取一个新目标的中心点(new_center_x, new_center_y)
        # top额外限制条件：新目标的中心点需要需要保证距离旧目标中心点的距离小于max_distance
        new_center_x_left_top = max(0, center_x-center_width//2-target_width//2-max_distance)
        new_center_x_right_top = min(img_width, center_x+center_width//2+target_width//2+max_distance)
        new_center_y_top_top = max(0, center_y-center_height//2-target_height//2-max_distance)
        new_center_y_bottom_top = center_y-center_height//2-target_height//2
        attempt += 1
        try:
            new_center_x = random.randint(max(new_center_x_left, new_center_x_left_top),
                                              min(new_center_x_right, new_center_x_right_top))
            new_center_y = random.randint(max(new_center_y_top, new_center_y_top_top),
                                              min(new_center_y_bottom, new_center_y_bottom_top))
        except ValueError:
            continue
        # 得到新目标左上角位置信息(xmin_s, ymin_s)
        xmin_s, ymin_s = new_center_x-target_width // 2, new_center_y-target_height//2
        xmax_s, ymax_s = xmin_s + target_width, ymin_s + target_height
        attempt_box = torch.tensor([xmin_s, ymin_s, xmax_s, ymax_s])
        # 添加top区域的候选框并记录相应陆地覆盖率
        top.append(attempt_box)
        top_score.append(count_ones_in_box(attempt_box, mask))

    """ 从限制条件内选取bottom的中心点 """
    attempt = 0
    while attempt < max_attempts:
        # 随机选取一个新目标target
        target = random.choice(data['instances'])
        if target._fields['gt_classes'] in [0, 1, 2]:
            continue
        # 获取新目标的中心点(center_x, center_y)以及宽度center_width和高度center_height
        center_box = target._fields['gt_boxes']
        cxmin, cymin, cxmax, cymax = center_box.tensor.to('cpu').numpy()[0].astype(int)
        center_x, center_y = (cxmax + cxmin) // 2, (cymax + cymin) // 2
        center_width, center_height = (cxmax - cxmin), (cymax - cymin)
        # 随机选取一个新目标的中心点(new_center_x, new_center_y)
        # bottom额外限制条件：新目标的中心点需要需要保证距离旧目标中心点的距离小于max_distance
        new_center_x_left_bottom = max(0, center_x-center_width//2-target_width//2-max_distance)
        new_center_x_right_bottom = min(img_width, center_x+center_width//2+target_width//2+max_distance)
        new_center_y_top_bottom = center_y-center_height//2-target_height//2-max_distance
        new_center_y_bottom_bottom = min(img_height, center_y-center_height//2-target_height//2)
        attempt += 1
        try:
            new_center_x = random.randint(max(new_center_x_left, new_center_x_left_bottom),
                                              min(new_center_x_right, new_center_x_right_bottom))
            new_center_y = random.randint(max(new_center_y_top, new_center_y_top_bottom),
                                              min(new_center_y_bottom, new_center_y_bottom_bottom))
        except ValueError:
            continue
        # 得到新目标左上角位置信息(xmin_s, ymin_s)
        xmin_s, ymin_s = new_center_x-target_width//2, new_center_y-target_height//2
        xmax_s, ymax_s = xmin_s + target_width, ymin_s + target_height
        attempt_box = torch.tensor([xmin_s, ymin_s, xmax_s, ymax_s])
        # 添加bottom区域的候选框并记录相应陆地覆盖率
        bottom.append(attempt_box)
        bottom_score.append(count_ones_in_box(attempt_box, mask))

    """ 从限制条件内选取left的中心点 """
    attempt = 0
    while attempt < max_attempts:
        # 随机选取一个新目标target
        target = random.choice(data['instances'])
        if target._fields['gt_classes'] in [0, 1, 2]:
            continue
        # 获取新目标的中心点(center_x, center_y)以及宽度center_width和高度center_height
        center_box = target._fields['gt_boxes']
        cxmin, cymin, cxmax, cymax = center_box.tensor.to('cpu').numpy()[0].astype(int)
        center_x, center_y = (cxmax + cxmin) // 2, (cymax + cymin) // 2
        center_width, center_height = (cxmax - cxmin), (cymax - cymin)
        # 随机选取一个新目标的中心点(new_center_x, new_center_y)
        # left额外限制条件：新目标的中心点需要需要保证距离旧目标中心点的距离小于max_distance
        new_center_x_left_left = max(0, center_x - center_width // 2 - target_width // 2 - max_distance)
        new_center_x_right_left = center_x - center_width // 2 - target_width // 2
        new_center_y_top_left = max(0, center_y-center_height//2-target_height//2-max_distance)
        new_center_y_bottom_left = min(img_height, center_y+center_height//2+target_height//2+max_distance)
        attempt += 1
        """ 从限制条件内选取left的中心点 """
        try:
            new_center_x = random.randint(max(new_center_x_left, new_center_x_left_left),
                                                 min(new_center_x_right, new_center_x_right_left))
            new_center_y = random.randint(max(new_center_y_top, new_center_y_top_left),
                                                 min(new_center_y_bottom, new_center_y_bottom_left))
        except ValueError:
            continue
        # 得到新目标左上角位置信息(xmin_s, ymin_s)
        xmin_s, ymin_s = new_center_x - target_width // 2, new_center_y - target_height // 2
        xmax_s, ymax_s = xmin_s + target_width, ymin_s + target_height
        attempt_box = torch.tensor([xmin_s, ymin_s, xmax_s, ymax_s])
        # 添加bottom区域的候选框并记录相应陆地覆盖率
        left.append(attempt_box)
        left_score.append(count_ones_in_box(attempt_box, mask))

    """ 从限制条件内选取right的中心点 """
    attempt = 0
    while attempt < max_attempts:
        # 随机选取一个新目标target
        target = random.choice(data['instances'])
        if target._fields['gt_classes'] in [0, 1, 2]:
            continue
        # 获取新目标的中心点(center_x, center_y)以及宽度center_width和高度center_height
        center_box = target._fields['gt_boxes']
        cxmin, cymin, cxmax, cymax = center_box.tensor.to('cpu').numpy()[0].astype(int)
        center_x, center_y = (cxmax + cxmin) // 2, (cymax + cymin) // 2
        center_width, center_height = (cxmax - cxmin), (cymax - cymin)
        # 随机选取一个新目标的中心点(new_center_x, new_center_y)
        # right额外限制条件：新目标的中心点需要需要保证距离旧目标中心点的距离小于max_distance
        new_center_x_left_right = center_x + center_width // 2 + target_width // 2
        new_center_x_right_right = min(img_width, center_x + center_width // 2 + target_width // 2 + max_distance)
        new_center_y_top_right = max(0, center_y-center_height//2-target_height//2-max_distance)
        new_center_y_bottom_right = min(img_height, center_y+center_height//2+target_height//2+max_distance)
        attempt += 1
        """ 从限制条件内选取right的中心点 """
        try:
            new_center_x = random.randint(max(new_center_x_left, new_center_x_left_right),
                                               min(new_center_x_right, new_center_x_right_right))
            new_center_y = random.randint(max(new_center_y_top, new_center_y_top_right),
                                               min(new_center_y_bottom, new_center_y_bottom_right))
        except ValueError:
            continue
        # 得到新目标左上角位置信息(xmin_s, ymin_s)
        xmin_s, ymin_s = new_center_x - target_width // 2, new_center_y - target_height // 2
        xmax_s, ymax_s = xmin_s + target_width, ymin_s + target_height
        attempt_box = torch.tensor([xmin_s, ymin_s, xmax_s, ymax_s])
        # 添加bottom区域的候选框并记录相应陆地覆盖率
        right.append(attempt_box)
        right_score.append(count_ones_in_box(attempt_box, mask))
    # 选择区域陆地覆盖率最低的方向
    region_scores = {'top': 1 if len(top_score) == 0 else np.average(top_score),
                     'bottom': 1 if len(bottom_score) == 0 else np.average(bottom_score),
                     'left': 1 if len(left_score) == 0 else np.average(left_score),
                     'right': 1 if len(right_score) == 0 else np.average(right_score)}
    name = min(region_scores, key=region_scores.get)
    scores = {'top': top_score, 'bottom': bottom_score, 'left': left_score, 'right': right_score}
    bboxes = {'top': top, 'bottom': bottom, 'left': left, 'right': right}
    if len(scores[name]) == 0:
        return None
    index = random.choice(np.argsort(scores[name])[:2])
    score, bbox = scores[name][index], bboxes[name][index]
    if score < iou_threshold:
        mask[bbox[1]:bbox[3], bbox[0]:bbox[2]] = 1
        return bbox
    else:
        return None


def merge_instances(data, exemplar_rehearsal, OLD_CLASSES, mode='both', device='cuda'):
    if mode not in ['both', 'none', 'target', 'sea_land']:
        raise ValueError(f"The mode value {mode} should be one in ['both', 'none', 'target', 'sea_land']")
    _, height, width = data['image'].shape
    mask = np.zeros([height, width])
    if mode == 'both' or mode == 'target':
        # 根据已有回归框的信息，构建mask掩膜矩阵
        for gt_box in data['instances']._fields['gt_boxes'].tensor:
            xmin, ymin, xmax, ymax = gt_box
            mask[int(ymin):int(ymax), int(xmin):int(xmax)] = 1
    if mode == 'both' or mode == 'sea_land':
        # 海陆分割得到的结果同样交集到mask掩膜矩阵
        img_path = os.path.join(folder, 'mid_' + data['file_name'].split('/')[-1])
        img = Image.open(img_path)
        img = img.resize((800, 800), Image.NEAREST)
        img = np.array(img)[:, :, 0] / 255.
        # 将海陆分割中元素为1的位置（陆地位置）在mask中同样设置为1
        """ 需要判断data是否经过数据增强 """
        if data['flipped']:
            mask[np.fliplr(img) == 1] = 1.
        else:
            mask[img == 1] = 1.
    """ 旧随机放置目标，保证旧目标与新目标、潜在内陆区域的IoU小于阈值 """
    for OLD_CLASS in OLD_CLASSES:
        for i in range(random.choice([0, 1, 2])):
            # instance[0]存储了旧目标的目标框信息于类别信息
            # instance[1]存储了旧目标的目标切片
            instance = random.choice(exemplar_rehearsal[OLD_CLASS])
            # 创建选中元素的深层副本
            instance_copy = copy.deepcopy(instance)
            _, height, width = instance_copy[1].shape
            # 根据mask掩膜矩阵信息适当调整旧目标切片instance的回归框信息，使得目标切片位于0位置
            # 不与新目标重叠且不与内陆区域重叠
            new_box = adjust_box_position([height, width], mask, data)
            if new_box == None:
                continue
            # 合并Boxes
            instance_copy[0]._fields['pred_boxes'].tensor[0] = new_box
            xmin, ymin, xmax, ymax = instance_copy[0]._fields['pred_boxes'].tensor[0].to('cpu').int()
            merged_boxes = Boxes(torch.cat([data['instances']._fields['gt_boxes'].tensor.to(device),
                                            instance_copy[0]._fields['pred_boxes'].tensor.to(device)], dim=0))
            # 合并CLASSES
            merged_classes = torch.cat([data['instances']._fields['gt_classes'].to(device), instance_copy[0]._fields['pred_classes'].to(device)], dim=0)
            # 创建新的Instances对象
            data['instances']._fields['gt_boxes'] = merged_boxes
            data['instances']._fields['gt_classes'] = merged_classes
            data['image'][:, ymin:ymax, xmin:xmax] = instance_copy[1]


def merge_instances_mixup(data, exemplar_rehearsal, OLD_CLASSES, mode='both', device='cuda'):
    if mode not in ['both', 'none', 'target', 'sea_land']:
        raise ValueError(f"The mode value {mode} should be one in ['both', 'none', 'target', 'sea_land']")
    _, height, width = data['image'].shape
    mask = np.zeros([height, width])
    if mode == 'both' or mode == 'target':
        # 根据已有回归框的信息，构建mask掩膜矩阵
        for gt_box in data['instances']._fields['gt_boxes'].tensor:
            xmin, ymin, xmax, ymax = gt_box
            mask[int(ymin):int(ymax), int(xmin):int(xmax)] = 1
    if mode == 'both' or mode == 'sea_land':
        # 海陆分割得到的结果同样交集到mask掩膜矩阵
        img_path = os.path.join(folder, 'Otsu_' + data['file_name'].split('/')[-1])
        img = Image.open(img_path)
        img = img.resize((800, 800), Image.NEAREST)
        img = np.array(img)[:, :, 0] / 255.
        # 将海陆分割中元素为1的位置（陆地位置）在mask中同样设置为1
        mask[img == 1] = 1.

    for OLD_CLASS in OLD_CLASSES:
        for i in range(random.choice([0, 1])):
            # instance[0]存储了旧目标的目标框信息于类别信息, instance[1]存储了旧目标的目标切片
            instance1, instance2 = random.sample(exemplar_rehearsal[OLD_CLASS], k=2)
            # 创建选中元素的深层副本
            instance1_copy = copy.deepcopy(instance1)
            instance2_copy = copy.deepcopy(instance2)
            # 提取切片的尺寸
            _, A, B = instance1_copy[1].shape
            _, C, D = instance2_copy[1].shape
            if A * B < C * D:
                instance2_copy[1] = resize_slice(instance2_copy[1], A, B)
            else:
                instance1_copy[1] = resize_slice(instance1_copy[1], C, D)

            p = np.random.beta(0.5, 0.5)
            instance1_copy[1] = p * instance1_copy[1] + (1 - p) * instance2_copy[1]
            _, new_height, new_width = instance1_copy[1].shape
            # 根据mask掩膜矩阵信息适当调整旧目标切片instance的回归框信息，使得目标切片位于0位置
            # 不与新目标重叠且不与内陆区域重叠
            new_box = adjust_box_position([new_height, new_width], mask)
            if new_box == None:
                continue
            # 合并Boxes
            instance1_copy[0]._fields['pred_boxes'].tensor[0] = new_box
            xmin, ymin, xmax, ymax = instance1_copy[0]._fields['pred_boxes'].tensor[0]
            merged_boxes = Boxes(torch.cat([data['instances']._fields['gt_boxes'].tensor.to(device),
                                            instance1_copy[0]._fields['pred_boxes'].tensor.to(device)], dim=0))
            # 合并CLASSES
            merged_classes = torch.cat([data['instances']._fields['gt_classes'].to(device),
                                        instance1_copy[0]._fields['pred_classes'].to(device)], dim=0)
            # 创建新的Instances对象
            data['instances']._fields['gt_boxes'] = merged_boxes
            data['instances']._fields['gt_classes'] = merged_classes
            data['image'][:, int(ymin):int(ymax), int(xmin):int(xmax)] = instance1_copy[1]


def filter_predictions_by_iou_and_class(predictions, targets, iou_threshold=0.9,device='cuda'):
    filter_predictions = []
    filter_slices = []
    indexes = []
    index = 0
    for pred, target in zip(predictions, targets):
        """ 获取预测目标框的坐标信息和类别信息 """
        pred_boxes = pred['instances'].pred_boxes
        # 推理尺寸为512*512，而训练图像缩放至800*800，因此需要将pred_boxes缩放至于800*800
        pred_boxes = Boxes(pred_boxes.tensor * 1.5625)
        pred['instances']._fields['pred_boxes'] = pred_boxes
        pred_classes = pred['instances'].pred_classes
        "“” 获取真实目标框的坐标信息和类别信息 “”"
        gt_boxes = target['instances'].gt_boxes
        gt_classes = target['instances'].gt_classes
        ious = pairwise_iou(pred_boxes, gt_boxes.to(device))
        for pred_idx in range(len(pred_boxes)):
            for gt_idx in range(len(gt_boxes)):
                if ious[pred_idx, gt_idx] > iou_threshold and pred_classes[pred_idx] == gt_classes[gt_idx]:
                    filter_predictions.append(pred['instances'][pred_idx])
                    xmin, ymin, xmax, ymax = pred_boxes.tensor[pred_idx]
                    filter_slices.append(target['image'][:, int(ymin):int(ymax), int(xmin):int(xmax)])
                    indexes.append(index)
            index += 1
        return filter_predictions, filter_slices, indexes


def count_ones_in_box(new_box, mask):
    """
    计算目标框内1的比例
    """
    xmin, ymin, xmax, ymax = new_box.int()
    return mask[ymin:ymax, xmin:xmax].sum() / ((xmax - xmin) * (ymax - ymin))


def judge_distribution(new_box, mask):
    """ 判断当前框局部信息的分布变化，如果分布差异不大则bnew_box可能是内陆，则返回 """
    xmin, ymin, xmax, ymax = new_box.int()
    height, width = int(ymax - ymin), int(xmax - xmin)
    expand_by = 15
    # 大局部像素比例计算
    new_xmin, new_ymin = max(xmin - expand_by, 0), max(ymin - expand_by, 0)
    new_xmax, new_ymax = min(xmax + expand_by, 800), min(ymax + expand_by, 800)
    p11 = mask[new_ymin: new_ymax, new_xmin:new_xmax].sum()
    p12 = (new_xmax - new_xmin) * (new_ymax - new_ymin)
    # 小局部像素比例计算
    p21 = mask[ymin:ymax, xmin:xmax].sum()
    p22 = height * width

    if (p11 - p21) / (p12 - p22) < 0.05:
        return True
    return False


def mixup(tea_feats, stu_feats, gts, mode='Uniform'):
    if mode not in ['Average', 'Beta', 'Uniform']:
        raise ValueError(f"The mode value {mode} should be one in ['average', 'Beta']")

    unique_classes = torch.tensor([0, 1, 2])    # 只对旧类目标进行RoI feats扩充（缓解灾难性遗忘问题）
    mixed_feats_tea, mixed_feats_stu, mixed_gts = [], [], []
    for cls in unique_classes:
        cls_indices = torch.where(gts == cls)[0]
        if len(cls_indices) < 2:
            continue

        cls_feats_tea = tea_feats[cls_indices]
        cls_feats_stu = stu_feats[cls_indices]
        num_samples = cls_feats_tea.size(0)
        indices = torch.randperm(num_samples)
        for i in range(0, num_samples - 1, 2):
            if i + 1 < num_samples:
                if mode == 'Average':
                    p1, p2 = 0.5, 0.5
                elif mode == 'Beta':
                    p1 = np.random.beta(2, 2)
                    p2 = 1 - p1
                elif mode == 'Uniform':
                    p1 = np.random.beta(1, 1)
                    p2 = 1 - p1

                mixed_feat_tea = p1 * cls_feats_tea[indices[i]] + p2 * cls_feats_tea[indices[i+1]]
                mixed_feat_stu = p1 * cls_feats_stu[indices[i]] + p2 * cls_feats_stu[indices[i+1]]
                mixed_feats_tea.append(mixed_feat_tea.unsqueeze(0))
                mixed_feats_stu.append(mixed_feat_stu.unsqueeze(0))
                mixed_gts.append(cls.unsqueeze(0))

    return torch.cat(mixed_feats_tea), torch.cat(mixed_feats_stu), torch.cat(mixed_gts)


def exemplar_mining(model_teacher, new_data, cls_thr=0.9, iou_thr=0.9, device='cuda'):
    """ Exemplar mining """
    with torch.no_grad():
        # New data is fed into the teacher model, generating prediction results
        predictions = model_teacher(new_data)
        for i, (prediction, gt) in enumerate(zip(predictions, new_data)):
            # Obtain the prediction results for the current image
            pred_boxes = prediction['instances']._fields['pred_boxes']
            scores = prediction['instances']._fields['scores']
            pred_classes = prediction['instances']._fields['pred_classes']

            # Only retain the prediction results with scores above the threshold (thr)
            pred_boxes = pred_boxes[scores > cls_thr]
            pred_classes = pred_classes[scores > cls_thr]
            scores = scores[scores > cls_thr]

            # Calculate the IoU between the predicted boxes and the ground truth boxes of the new classes,
            # and remove the predicted boxes with high IoU (IoU > 0.7)
            gt_classes = gt['instances']._fields['gt_classes'].to(device)
            gt_boxes = gt['instances']._fields['gt_boxes'].to(device)
            ious = pairwise_iou(pred_boxes, gt_boxes)
            max_ious, _ = ious.max(dim=1)
            keep = max_ious < iou_thr
            pred_boxes = pred_boxes[keep]
            scores = scores[keep]
            pred_classes = pred_classes[keep]

            # After the above processing, the prediction results only contain suspected old targets.
            # Finally, annotate the predicted boxes on the new data
            new_gt_boxes = Boxes(torch.cat([gt_boxes.tensor, pred_boxes.tensor], dim=0))
            new_gt_classes = torch.cat([gt_classes, pred_classes], dim=0)
            new_data[i]['instances']._fields['gt_boxes'] = new_gt_boxes
            new_data[i]['instances']._fields['gt_classes'] = new_gt_classes


def resize_slice(slice, height, width):
    transform = transforms.Compose([
        transforms.Resize((height, width)),
    ])
    resized_slice = transform(slice)
    return resized_slice


def show_image(data, mode, operate, iter):
    directory_path = 'out/PROCESS/' + str(iter)
    if mode not in ['replay', 'mixup']:
        raise ValueError(f'The mode should be one of the "replay" or "mixup".')
    for img in data:
        image = img['image'].permute(1, 2, 0).numpy()
        image = image / 255.
        plt.figure(figsize=(10, 10))
        plt.imshow(image)
        plt.axis("off")
        if operate == 'before':
            if not os.path.exists(directory_path):
                os.makedirs(directory_path)
            plt.savefig(directory_path + '/Before_' + mode +'_' + img['file_name'].split('/')[-1], bbox_inches='tight')
        else:
            plt.savefig(directory_path + '/After_' + mode +'_' + img['file_name'].split('/')[-1], bbox_inches='tight')

